import json
from sqlalchemy.orm import Session
from sqlalchemy import select
from google import genai
from google.genai import types

from app.core.config import settings
from app.core.prompts import StudyPrompts  # üëà –ù–æ–≤–∏–π —ñ–º–ø–æ—Ä—Ç
from app.models.document import Document, DocumentChunk
from app.models.analysis import ProjectAnalysis, ProjectAnalysisItem
from app.schemas.study import ExamResponse

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞
client = genai.Client(api_key=settings.GEMINI_API_KEY)

class StudyService:

    # --- HELPER METHODS ---

    def _get_docs_hash(self, documents_ids: list[int]) -> str:
        """–°—Ç–≤–æ—Ä—é—î —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π –ø—ñ–¥–ø–∏—Å –¥–ª—è –Ω–∞–±–æ—Ä—É —Ñ–∞–π–ª—ñ–≤"""
        return ','.join(map(str, sorted(documents_ids)))

    def _get_context(self, db: Session, project_id: int, document_ids: list[int] | None = None) -> str:
        """–í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç –∑ –±–∞–∑–∏"""
        stmt = (
            select(DocumentChunk.chunk_text)
            .join(Document)
            .filter(Document.project_id == project_id)
            .order_by(Document.id, DocumentChunk.chunk_index)
        )
        if document_ids:
            stmt = stmt.filter(Document.id.in_(document_ids))

        chunks = db.scalars(stmt).all()
        return "\n\n".join(chunks)

    def _generate_ai(self, prompt: str, schema=None) -> str | ExamResponse:
        """–Ñ–¥–∏–Ω–∞ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥—É –¥–ª—è –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ AI"""
        config = None
        if schema:
            config = types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=schema
            )

        try:
            response = client.models.generate_content(
                model="gemini-3-flash-preview",
                contents=prompt,
                config=config
            )

            if schema:
                # –Ø–∫—â–æ –æ—á—ñ–∫—É—î–º–æ JSON/Schema, –ø–∞—Ä—Å–∏–º–æ –π–æ–≥–æ
                return schema.model_validate_json(response.text)
            return response.text

        except Exception as e:
            print(f"AI Generation Error: {e}")
            return schema(questions=[]) if schema else "–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó."

    # --- CACHE LOGIC (–†–æ–±–æ—Ç–∞ –∑ –ë–î) ---

    def _get_full_project_cache(self, db: Session, project_id: int, field: str):
        """–®—É–∫–∞—î –∫–µ—à –¥–ª—è –≤—Å—å–æ–≥–æ –ø—Ä–æ—î–∫—Ç—É"""
        analysis = db.query(ProjectAnalysis).filter_by(project_id=project_id).first()
        if analysis:
            return getattr(analysis, field)
        return None

    def _save_full_project_cache(self, db: Session, project_id: int, field: str, value):
        """–ó–±–µ—Ä—ñ–≥–∞—î –∫–µ—à –¥–ª—è –≤—Å—å–æ–≥–æ –ø—Ä–æ—î–∫—Ç—É"""
        analysis = db.query(ProjectAnalysis).filter_by(project_id=project_id).first()
        if not analysis:
            analysis = ProjectAnalysis(project_id=project_id)
            db.add(analysis)

        # –î–ª—è –µ–∫–∑–∞–º–µ–Ω—É –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ dict, –¥–ª—è —Ç–µ–∫—Å—Ç—É - –ª–∏—à–∞—î–º–æ —è–∫ —î
        val_to_save = [q.model_dump() for q in value.questions] if field == "exam_questions" else value
        setattr(analysis, field, val_to_save)
        db.commit()

    def _get_partial_cache(self, db: Session, project_id: int, doc_hash: str, field: str):
        """–®—É–∫–∞—î –∫–µ—à –¥–ª—è –≤–∏–±—ñ—Ä–∫–∏ —Ñ–∞–π–ª—ñ–≤"""
        item = db.query(ProjectAnalysisItem).filter_by(project_id=project_id, documents_hash=doc_hash).first()
        if item:
            return getattr(item, field)
        return None

    def _save_partial_cache(self, db: Session, project_id: int, doc_hash: str, field: str, value):
        """–ó–±–µ—Ä—ñ–≥–∞—î –∫–µ—à –¥–ª—è –≤–∏–±—ñ—Ä–∫–∏ —Ñ–∞–π–ª—ñ–≤"""
        item = db.query(ProjectAnalysisItem).filter_by(project_id=project_id, documents_hash=doc_hash).first()
        if not item:
            item = ProjectAnalysisItem(project_id=project_id, documents_hash=doc_hash)
            db.add(item)

        val_to_save = [q.model_dump() for q in value.questions] if field == "exam_questions" else value
        setattr(item, field, val_to_save)
        db.commit()

    def _is_valid_result(self, result) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –≤–∞—Ä—Ç–æ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ —Ü–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É –±–∞–∑—É"""

        # 1. –Ø–∫—â–æ —Ü–µ –ï–∫–∑–∞–º–µ–Ω (–æ–±'—î–∫—Ç ExamResponse)
        if hasattr(result, "questions"):
            # –ù–µ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ, —è–∫—â–æ –ø–∏—Ç–∞–Ω—å –Ω–µ–º–∞—î
            return bool(result.questions)

        # 2. –Ø–∫—â–æ —Ü–µ –¢–µ–∫—Å—Ç (Summary, Key Points)
        if isinstance(result, str):
            if not result.strip():
                return False  # –ü—É—Å—Ç–∏–π —Ä—è–¥–æ–∫
            if "–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞" in result or result.startswith("Error:"):
                return False  # –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É
            if len(result) < 50:
                return False  # –ü—ñ–¥–æ–∑—Ä—ñ–ª–æ –∫–æ—Ä–æ—Ç–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
            return True

        return False
    # --- MAIN ORCHESTRATOR (–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è) ---

    def _process_request(self, db: Session, project_id: int, document_ids: list[int] | None, field_name: str, prompt_template: str, response_schema=None):
        """
        –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –º–µ—Ç–æ–¥, —è–∫–∏–π:
        1. –ü–µ—Ä–µ–≤—ñ—Ä—è—î –∫–µ—à (–ø–æ–≤–Ω–∏–π –∞–±–æ —á–∞—Å—Ç–∫–æ–≤–∏–π).
        2. –Ø–∫—â–æ –ø—É—Å—Ç–æ -> –±–µ—Ä–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        3. –ì–µ–Ω–µ—Ä—É—î —á–µ—Ä–µ–∑ AI.
        4. –ó–±–µ—Ä—ñ–≥–∞—î –≤ –∫–µ—à.
        """

        # 1. –°–ø—Ä–æ–±–∞ –≤–∑—è—Ç–∏ –∑ –∫–µ—à—É
        cached_data = None
        if not document_ids:
            cached_data = self._get_full_project_cache(db, project_id, field_name)
        else:
            doc_hash = self._get_docs_hash(document_ids)
            cached_data = self._get_partial_cache(db, project_id, doc_hash, field_name)

        if cached_data:
            # –Ø–∫—â–æ —Ü–µ –µ–∫–∑–∞–º–µ–Ω, –≤—ñ–¥–Ω–æ–≤–ª—é—î–º–æ Pydantic –º–æ–¥–µ–ª—å –∑ JSON
            if response_schema:
                return response_schema(questions=cached_data)
            return cached_data

        # 2. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è (—è–∫—â–æ –∫–µ—à—É –Ω–µ–º–∞—î)
        context = self._get_context(db, project_id, document_ids)
        if not context:
            return response_schema(questions=[]) if response_schema else "–¢–µ–∫—Å—Ç –≤—ñ–¥—Å—É—Ç–Ω—ñ–π."

        # –§–æ—Ä–º—É—î–º–æ –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ —à–∞–±–ª–æ–Ω
        full_prompt = prompt_template.format(context=context)

        result = self._generate_ai(full_prompt, schema=response_schema)

        # 3. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        if self._is_valid_result(result):
            if not document_ids:
                self._save_full_project_cache(db, project_id, field_name, result)
            else:
                self._save_partial_cache(db, project_id, self._get_docs_hash(document_ids), field_name, result)
        else:
            print(f"Warning: Invalid result for {field_name}: {result}")

        return result

    # --- PUBLIC API METHODS (–¢–µ–ø–µ—Ä –≤–æ–Ω–∏ –¥—É–∂–µ –ø—Ä–æ—Å—Ç—ñ) ---

    def get_summary(self, db: Session, project_id: int, document_ids: list[int] | None) -> str:
        return self._process_request(
            db, project_id, document_ids,
            field_name="summary",
            prompt_template=StudyPrompts.SUMMARY
        )

    def get_keypoints(self, db: Session, project_id: int, document_ids: list[int] | None) -> str:
        return self._process_request(
            db, project_id, document_ids,
            field_name="key_points",
            prompt_template=StudyPrompts.KEY_POINTS
        )

    def get_exam_questions(self, db: Session, project_id: int, document_ids: list[int] | None) -> ExamResponse:
        return self._process_request(
            db, project_id, document_ids,
            field_name="exam_questions",
            prompt_template=StudyPrompts.EXAM_GENERATION,
            response_schema=ExamResponse
        )

    def answer_user_questions(self, db: Session, project_id: int, questions: list[str], document_ids: list[int] | None) -> str:
        # –¢—É—Ç –∫–µ—à—É–≤–∞–Ω–Ω—è –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–µ, —Ç–æ–º—É –≤–∏–∫–ª–∏–∫–∞—î–º–æ –Ω–∞–ø—Ä—è–º—É
        context = self._get_context(db, project_id, document_ids)
        if not context: return "–ù–µ–º–∞—î –∫–æ–Ω—Ç–µ–∫—Å—Ç—É."

        q_list_str = "\n".join([f"- {q}" for q in questions])
        full_prompt = StudyPrompts.USER_QUESTION.format(questions_list=q_list_str, context=context)

        return self._generate_ai(full_prompt)

study_service = StudyService()