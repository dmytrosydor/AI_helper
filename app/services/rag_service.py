from google import genai
from google.genai import types # <--- –î–æ–¥–∞–Ω–æ —ñ–º–ø–æ—Ä—Ç types
from app.core.config import settings
from app.core.db import AsyncSessionLocal
from sqlalchemy import select
from app.models.document import Document, DocumentChunk
from app.services.pdf_service import pdf_service

client = genai.Client(api_key=settings.GEMINI_API_KEY)

class RagService:
    def get_embedding(self, text: str) -> list[float]:
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ text-embedding-004
            result = client.models.embed_content(
                model="gemini-embedding-001",
                contents=text,
                config=types.EmbedContentConfig(output_dimensionality=768)
            )
            print("Result:", result)
            # –í SDK genai —Ü–µ –∑–∞–∑–≤–∏—á–∞–π –∞—Ç—Ä–∏–±—É—Ç values, –∞ –Ω–µ —Ñ—É–Ω–∫—Ü—ñ—è values()
            return result.embeddings[0].values
        except Exception as e:
            print(f"Gemini API Error: {e}")
            return []

    async def process_document(self, document_id: int):
        # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ –≤–ª–∞—Å–Ω—É —Å–µ—Å—ñ—é
        async with AsyncSessionLocal() as db:
            print(f"--- üöÄ Start processing document ID {document_id} ---")

            stmt = (
                select(Document)
                .filter(Document.id == document_id)
            )
            result = await db.execute(stmt)
            document = result.scalars().first()

            if not document:
                print("‚ùå Document not found in DB")
                return

            # 1. –ü–æ—á–∏–Ω–∞—î–º–æ –æ–±—Ä–æ–±–∫—É: —Å—Ç–∞—Ç—É—Å "processing"
            document.processing_status = "processing"
            await db.commit()

            try:
                full_text = pdf_service.extract_text(document.file_path)

                if not full_text:
                    print(f"‚ö†Ô∏è Document {document.id} has no text")
                    # –ü–æ–º–∏–ª–∫–∞: –ø—É—Å—Ç–∏–π —Ç–µ–∫—Å—Ç
                    document.processing_status = "failed"
                    await db.commit()
                    return

                chunk_size = 1000
                overlap = 100
                chunks = []

                for i in range(0, len(full_text), chunk_size - overlap):
                    chunk = full_text[i : i + chunk_size]
                    if len(chunk) > 50:
                        chunks.append(chunk)

                print(f"‚úÇÔ∏è Created {len(chunks)} chunks. Vectorizing...")

                new_chunks = []
                for idx, chunk_text in enumerate(chunks):
                    vector = self.get_embedding(chunk_text)

                    if vector:
                        db_chunk = DocumentChunk(
                            document_id=document.id,
                            chunk_index=idx,
                            chunk_text=chunk_text,
                            embedding=vector,
                        )
                        new_chunks.append(db_chunk)

                if new_chunks:
                    db.add_all(new_chunks)
                    # 2. –£—Å–ø—ñ—Ö: —Å—Ç–∞—Ç—É—Å "completed"
                    document.processing_status = "completed"
                    await db.commit()
                    print(f"‚úÖ Successfully saved {len(new_chunks)} chunks")
                else:
                    print(f"‚ö†Ô∏è No chunks were created/saved")
                    # –ü–æ–º–∏–ª–∫–∞: —á–∞–Ω–∫–∏ –Ω–µ —Å—Ç–≤–æ—Ä–∏–ª–∏—Å—å
                    document.processing_status = "failed"
                    await db.commit()

            except Exception as e:
                print(f"‚ùå Error processing document: {e}")
                # 3. –ì–ª–æ–±–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞: —Å—Ç–∞—Ç—É—Å "failed"
                document.processing_status = "failed"
                await db.commit()


rag_service = RagService()
